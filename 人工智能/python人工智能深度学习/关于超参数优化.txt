1.Learning rate
	过低的学习率导致训练结束还是得不到一个较好的结果，虽然loss一直减少
	
	过高的学习率导致loss降低一会后，开始持与稳定，得不到最优结果

2.Minibatch Size
批处理大小，过小导致训练过慢，太大又会降低模型的准确率


3.Number of Hidden Units/Layers
隐藏层的神经元个数过多，可能会导致overfitting，太少则导致学习到的东西少，学习效率低。

隐藏层的层数一般为2-3层，之后增加层数不会增加模型准确率，但是往往卷积学习是越深越好


4.RNNs的超参数
LSTM与GRU对比，LSTM更常用，但在不同的需求下，取决于任务和数据集大小